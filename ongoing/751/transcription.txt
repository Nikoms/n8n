[Music] hello my name is Dre humble I'm working in site reliability engineering at Google and I'm here to talk about developer productivity What It Is What It Isn't and how to improve it so if you just want the short version and you want to go and have a cup of tea or a beer at any point here is the single page summary first of all we have lots of bad productivity measures in software and I'm going to talk a bit about those and why they're bad there is however a good and valid and reliable way to measure software delivery performance in order to get better at software delivery performance there's a combination of technical Process Management and product development capabilities that you can invest in which will drive improved culture and improved performance culture can be me measured and changed and we'll talk about how to do that and finally it is actually possible to measure individual productivity although not perhaps in the way that you might expect and that can also be improved there's also a little bonus on coid and remote work which we'll cover right at the end so let's start with the problems with the kind of ways that we often see teams recording productivity at the moment so first of all no one should be doing this anymore but it's a good illustration people measuring lines of code as a measure of productivity and of course this is a measure of output the amount of work you do but it's always important to remember given a solution with 10,000 lines of code and a solution with 10 lines of code which would we prefer typically we would prefer the solution with 10 lines of code assuming that it's easy to read and understand what's going on over a solution with 10,000 lines of code because lines of code ultimately are as much of a liability as they are anything else you have to maintain those lines of code over time the more lines of code you have the harder it is to understand the software and if you need to change the software the harder it is to change the software uh because you have to understand what's going on and the implications of what you're doing so in general we prefer to solve problem s by writing the least possible code we can and ideally by deleting codes there's a great story from the early days of the Mac where uh one of the engineers uh deleted uh 10,000 lines of codes in the course of simplifying a program that had been written and at the end of the week they filled in a time sheet with how many lines of code that written that week and he put in minus you know x000 and uh that caused the project managers to freak out a little bit until he explained well actually the new solution is much better so if we can delete lines of code or avoid writing lines of code at all that in my opinion is a good day and it demonstrates why it's silly to measure lines of code as a measure of productivity uh because actually what we care about is outcomes not output which is a theme we'll return to a bit later so obviously there's a limit to this um you know it's typically possible to solve many problems by writing a single line of pearl which is completely impossible to understand and we don't necessarily want to recommend that so you know not that I got anything against Pearl I'm I'm a big fan of pearl but the point is you want to make sure your code is easy to understand and and and read and change and and that's important too so again it's not a number we want to minimize necessarily either but we certainly don't want to maximize it and it it's unfortunate even today when we know that lines of code is a silly measure I've still heard at performance reviews people talking about you know well look at the size of this CL that's such a substantial contribution well who cares how big the the change is what's important is the impact of that change on on the the system and the end users and the organization let's move on to another measure of productivity that is bad and that is velocity so velocity is a very common measure uh in agile teams excuse me um where it's used to measure the amount of work you did in an iteration so what happens here is at the beginning of the iteration we get together and we estimate the work that is to be done in in some uh relative size which might be uh T-shirt size or Gummy Bears or or story points or whatever we choose to do and then at the end of the iteration we see how many stories were complete and we add up the uh points uh for those stories and that gives us the velocity that we achieved in the iteration now the reason we do this is so that we can not overpromise in the next iteration it's actually a capacity management tool it's so that we don't take on more work than we can complete and that's what it's designed for however in many organizations velocity has become used as a productivity measure a way to see how much a team has done and there are many problems with this the first problem is that velocity simply wasn't designed in this way it's a relative measure and things like um how a team does their work what tools they're using um even the the the amount of Lights in the room all kinds of things can change velocity it's not designed to be used to compare teams it's a relative measure you can't compare it across teams you certainly can't aggregate it across a whole organization and expect to get any kind of meaningful number so that that's a terrible idea it also discourages teams from working together if my focus is how can I get the highest velocity another team asks for some help and that help is not going to contribute to my velocity um I'm more likely to not help that other team and that's very problematic in software in particular we is very common to have dependencies between teams and unless we actually focus on our overall organization goals and and um helping achieve those it's really easy to optimize locally and try and get my velocity really high um and and not help other teams and and that can actually cause huge problems and slow down the program or project or product as a whole so that that is the second problem um the third problem is that you then find that people start gaming it um it's very easy for people to start padding their velocity and and uh and saying things are going to take more points than they should because then they'll get more points at the end of the year iteration so uh this is good Hearts law when something becomes a Target uh it stops being useful as a measure so very important not to use velocity as a measure of productivity for these reasons the third thing that people often do is look at utilization which is how busy are you you know are are you uh spending all your 40 plus hours a week doing productive things rather than on things that are you know not related to delivering features uh and sometimes shows itself with teams which ask for time to do things like test automation or refactoring or uh other activities to reduce what's known as technical debt which are the um problems in the internal structure of the codes uh that slow us down and what happens then is over time you find that the software uh and the system that you're working in with it becomes more and more painful to work with and you end up uh slowing down and delivering more and more slowly and painfully and and that's a huge problem um actually we always want to have spare capacity in our delivery process in our teams because that's what we need a to take care of things like uh test Automation and refactoring and those things that help speed us up and and make us fast but also because we need to be able to deal with unexpected things when things go wrong when things happen that we don't expect uh we need spare capacity to to handle those things um otherwise what happens is uh you just end up thrashing between the work you're supposed to be doing and the new things that come up teams get burnt out um people get sick uh and you actually end up slowing down and you can demonstrate this mathematically so very important for teams to have slack time um when you're planning software um teams work over the next few months always make sure you leave spare capacity at least 20% of capacity spare so that you have capacity to absorb the things that are going to happen that you don't expect um either just because of external events or because you know inevitably planning is an imperfect activity so three things that it's common to measure for productivity they're all bad what can we do to get better at measuring productivity three things to consider first of all productivity should never be measured at the individual level I think a lot of managers um well maybe that's unly pessimistic but there's certainly some managers out there who would like to be able to stack rank their teams in order of most productive to least productive but the reality is that software development is a team sport it's something that can only be accomplished by teams and much of building High performing teams is about team culture as we'll see later and creating teams where people can work together effectively communication collaboration these of course are principles of the agile Manifesto and you don't actually want you know rock stars heroes in in that situation you want teams where people work together effectively and communicate and coordinate effectively and and help each other out and learn the appropriate skills to fill the gaps in the team so um it's actually not a good idea to measure individual productivity um in in the sense of you know people's output or or the outcomes that individ produce because that can discourage people working effectively in teams um secondly we want system level outcomes the whole reason that Dev Ops became a thing in the first place is because developers were measured on velocity and Ops was measured on stability and those two different measures tend to come into conflict when developers aren't responsible for quality or stability uh it's very easy to fall into the Trap of producing bad quality code that's not very stable or reliable just not because people are evil or stupid but because they're not connected to the consequences of their of their outcomes there's no feedback Le there and in the same way if Ops is rewarded by stability but not by velocity it's very easy to create a barrier um typically manifested it in the form of a very complex and bureaucratic change management process as a way to preserve stability at the expense of velocity so we want a system level outcome um that doesn't reward people for uh one aspect of performance at the expense of another which then tends to bring teams into conflicts with each other and finally we don't want to measure output we want to measure is outcomes in order to achieve um efficiency and effective teams we want to do the minimum output to reduce the maximum impacts or or outcome uh that's always what we're trying to do in the context of product development and software delivery so with that in mind um we have found over the course of the last uh well six years now of state of devops reports um that we worked on um Dora devops research and assessment the company I co-founded with Dr Nicole forren who is the principal investigator of This research program uh originally done with puppet now done with Google clouds uh which is where I work now um which acquired Dora we found a valid and reliable way to measure software delivery performance using these four metrics deploy frequency lead time for changes change fail rate and time to restore service so two speed metrics deploy frequency how frequently you deploy and lead time for changes how long it takes you to get changes from starting working Version Control to live in production and then to stability metrics change fail rate when you push a change to production what percentage of the time do you need to remediate in some way and then time to restore service when there's some kind of incident in production how long does it take he to uh remediate that problem so these four metrics we found um impact organizational performance they drive higher levels of productivity profitability and market share and they also Drive higher levels of quality of customer satisfaction and of the ability to achieve organizational and Mission goals so these four metrics we discovered in our program Drive improved organizational performance so they matter to your organization the other fascinating thing um that we found and in addition to the fact that as you can see here um the people who do best at this are twice as likely to meet or exceed those organizational goals is that organizations are not trading off speed against stability we traditionally think of speed and stability as a zero some game as a trade-off hence the phrase uh move fast and break things that's not what we find every year we've actually looked at the data what we found is that Elite performers are actually delivering faster and more stable um uh deployments so the delivery process for Elite Performance is more stable and faster as well so Elite performers are able to deploy on demand multiple times per day takes them less than a day to get their changes life um they can typically restore service in less than an hour and their change fail rate is in this um lowest bucket which is the 0 to 15% bucket if you go to the other end low performers are deploying between once every month and once every six months um and their lead time for changes is is the same because they're doing releases in these big bang batches um their time to restore service is is really slow it's between a week and a month and we think what's going on here is um you know you might be able to uh very quickly get the system um back up and and running but you're not fully actually restoring service in in this time um it might take longer it might take several days or several weeks to actually fully fix the problems that you find particularly in the event of uh security breaches it can take a long time to go and uh clear out any um problems that you find and and fix database issues and so forth and then finally the change rate is in this um 46 to 60% bucket so that's problematic we found these results to be valid across all different kinds of organizations as well we find that they hold constant across industry um and across organizational size uh we find high performers in organizations that are highly regulated uh with 10,000 or more employees we also find uh low performers in small organizations in Tech organizations as well um what we find is that large organizations tend to be very heterogenous you might find some teams that are high performers some teams that are low perform forers and that tends to change over time organizations are not um they're not homogeneous they they do have large levels of variation within them uh and and and that's what we we think is going on in the data but you can certainly be in a large highly regulated organization and achieve a leite performance it's it's hard it takes time takes investment but it is absolutely possible so if you are not in a high or Elite performing team how do you get better well there are a large number of factors actually that impact performance and uh over the years we've uh created this diagram which we lovingly call the BFD or big and friendly diagram and you can go to this link bit. l/- BFD to get the whole thing uh including an interactive version you probably won't be able to read this but I just want to point out the high level picture what we see is um in the middle on the right is organizational performance and software liery performance and then driving it are a few things firstly culture drives both software delivery performance and organizational performance and then on the left hand side there's a whole cluster of things that drive software delivery performance and in some cases culture as well um firstly a whole set of technical practices um that together comprise continuous delivery secondly some lean management practices and thirdly some lean product development practices and then driving both the product development and Technical practices is effective leadership so that's the kind of high level picture effective leadership enables teams to experiment with and Implement these Technical and management practices and then it's these practices that drive improved performance either directly or by driving improved culture which in turn drives performance and then both culture and performance Drive improved organizational performance just going to do a deep dive into a very few of these things uh in the time that we have firstly I'm going to start with continuous delivery so continuous delivery fundamentally is about making releases boring we want software delivery to be a push button event that we can perform at any time uh including evenings and weekends and it should be something that's very lowrisk and and repeatable and we can use it for all kinds of changes whether those are networking changes database changes software releases any kind of change to our production systems or to the apps our users are running should be able to be done safely and quickly and sustainably how do we do that well it's actually hard and there are a number of things that go into it you can see there's 14 practices that uh we have found in our research program to drive continuous delivery um from things like trunk-based development and continuous integration right through to things like monitoring and observability and proactive notifications um from production things like database change management how we maintain our codes uh there's actually a number of things that drive continuous delivery so it's it's a pretty holistic picture um and again I don't have time to cover all of these things um I'm going to do a little Deep dive into a few of them uh I will also note that these practices uh together that comprise continuous delivery don't just drive improve performance and culture they also lead to teams that are less burnt out um that experience less pain during the deployment process and that see less rework um and this is a nice proxy variable for Quality um what this means is by giving people the tools to build quality in uh they build a good quality work product that we find less defects in Downstream meaning that we have to do less rework because it wasn't done right the first time and so that really is the theme of the practices of continuous delivery is this idea of building quality in um this is a quote from W Edwards Deming one of the founders of the lean movement he has 14 points About Management one of them is Cease dependence on Mass inspection to achieve quality improve the process and build quality into the product in the first place and this is absolutely true of software again it's not that developers are dumb or stupid it's that they often lack the tools to actually get feedback on the work they're doing and find out if uh not only does it it not introduce defects and is it correct but also have we performance problems have we introduced security problems um have we introduced usability problems we need to get fast feedback on on the work that we do in order to find out if I actually delivered the expected value and this is the job of the deployment pipeline which is the key patent in continuous delivery the idea is that every time you make a change to any part of the system that should be done in Version Control it should trigger some very quick tests that tell us if we did anything really dumb typically unit test and maybe um uh an accept test or or two just to make sure that the system is basically working um they run in a few minutes and uh the moment those tests break we fix them straight away um and then we have a build that goes Downstream for more comprehensive testing more comprehensive un um acceptance tests initially uh and then once the builds passed the automated tests it goes Downstream for more comprehensive forms of testing such as exploratory testing usability testing performance testing testing and the idea is that these things should all be done um as soon as possible after check-in so instead of having this phased approach where we do you know software development and then we do a testing phase and then we do a phase for infos to try and find any security flaws instead we do all those things in process um very rapidly uh on a per change basis rather than on a per release basis and find and fix the problem straight away so that's the deployment pipeline at a glance the key pattern in continuous delivery and what we're trying to optimize for uh as we saw those four metrics um lead time deploy frequency time to restore change fail rate in the context of the deployment pipeline we need to really focus on lead time how long does it take us to get changes from check-in to release and a good question to ask yourself obviously on a per change bis that's going to form a distribution a good question to ask yourself if you don't know that number off the top of your head and many teams is this question asked by Mary and Tom pendick in implementing lean software development how long would it take your organization to deploy a change that involves just one single line of code and can you do that on a repeatable reliable basis so if you had to just change a single line of code how long would it take you to get that change out not with your emergency change process where you skip a bunch of things but in your regular process and try and work on optimizing that and that's what the practices of continuous delivery allow you to do in a way that not not only helps you get faster but also helps you improve your stability and reliability and lead time is important not just for velocity but for those things as well a great example of this is infosec um if you discover a vulnerability in your stack uh in some component or library that you use lead time is really important how quickly can we find all the applications that are impacted by that vulnerability and fix and redeploy them so that we're no longer vulnerable that's fundamentally a leadtime problem um over two years ago now there was the uh famous Equifax breach and that was caused by a version of Apache struts that um the teams just didn't know was in production and so didn't fix and as a result hackers were able to break into Equifax and exfiltrate user data um and and and and that was a huge problem so this is the kind of problem that continuous delivery helps with through things like comprehensive configuration management through automated uh testing including automated security testing and through being able to do uh fast and reliable deployments um this is exactly the kind of problem it helps with which is why continuous delivery isn't just about speed it's also about building more stable and secure and reliable systems as well we find actually in our research that uh teams that do well at those 4 key metrics also are able to do better at security as well um building security into software uh imp into the software development process improves performance and security quality those Elite performers are able to find and fix defects uh security problems more quickly um and they do that by running security tests as part of the deployment Pipeline and from this shift where infos is no longer the gatekeeper but instead is a team that enables development teams by making it easy to consume preapproved libraries by helping developers um improve their processes and tool trains and build Security in rather than relying on infos as as a gatekeeper one other thing that I want to focus on a bit is uh architecture and when people think about architecture and continuous delivery it's very easy to focus on things like Docker and kubernetes um and you know these are great Technologies no doubt um but they're important in as much as they achieve or they help you achieve certain outcomes rather than in and of themselves what we found is that one of the strongest predictors of the ability to practice continuous delivery is whether teams could answer yes to these five questions first can my team make large scale changes to the design of its system without the permission of someone outside the team or depending on other teams number two can my team complete its work without needing fine grain communication and coordination with people outside the team can my team deploy and released its product or service on demand independently of other services the product or service depends on can my team do most of its testing on demand without requiring an integrated test environment and finally my favorite CD metric can my team perform deployments during normal business hours with negligible downtime that for me is is a key metric um we shouldn't rely on um planned downtime outside of business hours to perform our releases it's absolutely possible to do um zero downtime releases during normal business hours even in large complex regulated organizations and that's what we should be aiming for but it does depend on these other factors both uh in terms of systems architecture like being able to do testing on demand uh and deployments On Demand without requiring um kind of complex dependencies and orchestration but also in teams being able to get their work done without dependencies as well so a big part of um achieving this is how we design our organizations and how we design our Enterprise architecture to try and remove dependencies between teams and between services so that we can um make changes to them uh and and get those changes delivered U rapidly and repeatably without all this complex orchestration which is incredibly timec consuming and and slow that's really hard work it takes lots of time you can do it with mainframes we've seen organizations like sunp in Australia who've been able to achieve this with with mainframes and other organizations as well there's a great case study of Ticket Master um taking their VMS uh sorry their vac space system and and and moving it to a more modern architecture um so you can do it with with Mainframe systems you can also use the latest wizzy kubernetes uh microservices architecture and not achieve these outcomes and that's really bad because you're wasting all your money so as you're doing technology shifts make sure that you're actually achieving these outcomes as you implement those things because that's really the important thing and um too few teams focus on these architectural outcomes so we'll come back to this a little bit later uh I do want to talk about Cloud as well lots of organizations moving to the clouds and Cloud can make a huge impact we found in our research that Elite performers were 24 more times more likely to be using the cloud if they did it right and again doing it right is is really key um nist uh the US Federal government's National Institute of Standards and Technology defines the clouds based on these five characteristics firstly on demand Self Service which means that as a user of the cloud I can get what I want straight away using an API rather than having to raise a ticket or send an email number two broad network access I can access the cloud services on any device that I I want um resource pooling um which means um a smaller number of physical devices serving a a much larger number or hosting a much larger number of virtual devices so virtualization if you will and resource consolidation um rapid elasticity which is the illusion of infinite resources I should be able to scale up and scale down um on demand and finally measured service which is that I only pay for what I actually use um so it's this move from a a capex based uh system to an Opex space system where I only uh pay for what I use what we found is that um only 29% of people who said they were using the cloud actually met these five characteristics it's unfortunately very common si in Enterprises to see orgs that adopt the cloud but the developer outcomes are unchanged you know before the clouds I had to wait 5 days to get a test environment by raising a ticket in in service now well guess what I still have to wait 5 days and raise a ticket in service now except that now it's done on the cloud instead of on on my previous Hardware in the data center well you didn't change anything you just spent a lot of money and and you haven't changed your stlc outcomes at all so that's very problematic um but organizations that do adopt new modern ways of using infrastructure uh such as infrastructure as code or or giops um and who change their processes around uh to to use their infrastructure in a cloud native way see this huge Improvement um Elite Performance of 24 times is more likely um to be using Cloud um that's a correlation so it could go the other way as well people who using cloud is only four times more likely to be elite performers it can make a huge difference so I want to switch gear a bit and talk about some of these management and product development practices and what we find is that uh these things kind of go together um lean management practices limiting working process visual management so we can actually see the quality of the work we're doing through displays like um build monitors and and so forth um getting feedback from production on on what's Happening so that we can make decisions based on what's happening in production and a lightweight change approval process where change approvals are done internally within the teams through pair programming or code review rather than by external bodies like change advisory uh change advisory boards teams need to do those things together to see Improvement you can't just do one uh of them and see Improvement you need to do those things together but they're very powerful they drive improved software delivery performance and they lead to teams that are less likely to be burnt out there's also a set of product development practices that um are important and have a huge impact such as working into more batches so taking big trunks of stuff and breaking them up into smaller trunks um and and delivering those smaller Trunks and then um delivering your um features uh iteratively and incrementally in small batches making that flow of work visible using things like um Can band boards or story boards or other um kind of visual uh displays that allow you to see the flow of work Gathering and actually implementing customer feedback and then enabling teams to experiment with what they're doing so common unfortunately still to see agile Transformations implemented by sending everyone to the you know to day course um and uh you must exactly follow the agile principle s and practices as laid out here and no deviation will be permitted well guess what that's not agile the whole point of agile is um to learn by doing and to experiment and um improve in a scientific way um and that means teams need to be able to experiment with new ideas teams need to experiment be able to experiment with with features as well um with uh new ways of doing things and delivering their work and and the the features they actually deliver um and we find that those things together Drive improved software delivery performance they also directly Drive improved organizational performance and they drive culture furthermore software delivery performance when when that gets better that also drives lean product development practices so there's a nice kind of virtual a circle going on here because guess what you can't do things like um Team experimentation unless you can deliver rapidly and see the impacts of that um so one of the biggest shifts that I've seen in the last 10 years is building user experience research uh and AB testing and other practices like that into the software delivery life cycle and giving teams the authority and tools and ability to try things out and see the impact on users and then uh iterate uh accordingly based on on what they learn so that's hugely important but it does depend on the ability to actually get changes released uh to users quite rapidly so that you can do that uh that kind of learning that's critical to building um high quality products that deliver the EXP expected impacts to users and to our organizations I want to shift a bit and talk about culture um we talk I've kind of mentioned it parenthetically a few times now how do we measure culture well we use this model from a sociologist called R westr he talks about uh culture on the basis of these six different axes you can see um and based on these six different measures he divides organizations up into pathological or power oriented organizations bureaucratic or rule oriented organizations and then finally generative or performance oriented organizations and what kind of organization you are depends on these six things that he looks at how effectively do we cooperate across teams and up and down the organization how do we deal with Messengers who bring us bad news do we shoot people who bring us bad news do we ignore people who bring us bad news or do we train people to bring us bad news so that we can act quickly while problems are still uh easy to fix before they become come huge catastrophic cascading failures how do we deal with responsibilities do we avoid them because we know that if something goes wrong I'm going to get in trouble are they defined narrowly so that when something goes wrong we know exactly who to blame or do we share risks because we know that we succeed or fail as a team how do we deal with bridging between different um parts of the organization is that discouraged you know don't go and tell the product people what we're doing we don't want them to find out we're going to spend some time refactoring um or is that encouraged um do we go and talk to each other about what we're doing and find win-win Solutions and then two things that are really two sides of the same coin how do we deal with failure and how do we deal with novelty in pathological organization failure leads to scapegoating we find whose fault it was and punish them so you know it was jez's fault let's fire jez well guess what in complex systems failure is inevitable and so if you fire JZ the next person to get jez's job might well find themselves in the same situation but without jez's experience and make the same mistake and really when something goes wrong we want to start with finding the person who was kind of in the middle of that and then asking how could we get that person better information how can we get that person better tools so that they can find uh those unanticipated consequences um more quickly um how can we improve the system and how can we improve um how that system processes information which is what's CRI here and then in organizations where failure leads to scapegoating no one wants to try anything new because new things have a higher chance of failing and if novelty is crushed no one's going to want to try anything new because it's too risky uh and so that's what you find in in organizations which are uh very pathological is that no one innovates either we just keep on doing the same thing because that's the Le least risky thing to do you're not going to get punished for that um that research was actually uh reinforced by research that was done at Google which found the same thing um Google was looking at how to build High performing teams and what they found is that the biggest Factor was psychological safety team members feel safe to take risks and be vulnerable in front of each other which might sound kind of very soft skills Z but actually again in teams it's the soft skills that enable you to move rapidly and build up trust um and and and and experiment with things uh you're not going to do that unless you trust each other and so building teams where the teams the people in the teams trust each other and and and feel vulnerable and are able to take risks is actually one of the most important things you can do as a manager or a leader and the only way you can do it is by constantly demonstrating that behavior and reinforcing it um by you know if something goes wrong not punishing that person but using that experience to learn lessons and and help the organization become more effective so leaders have got to model this Behavior over and over again um that's what helps build up trust that it's for real rather than you know just just saying it um so I just want to uh spend a few minutes talking about individual productivity as well um so I said earlier that individual productivity is is not a thing that we should be measuring um because it's teams that get things done not individuals and that's true in 2019 we did actually look at individual productivity but not in the sense of you know how many lines of code you could write or your velocity or or anything like that we looked at how it feels to be productive the feeling of productivity that you have um and what we asked people about is the extent to which they felt able to get complex time conceiving tasks completed with minimal distractions and interruptions and you can kind of think of about this like the ability to to achieve flow um this is very important in knowledge work uh where we are using her istics and and we're synthesizing and we're experimenting um in these complex systems the soci Technical Systems we operating with um so productivity um again the ability to get complex timec consuming task completed with minimal distractions and interruptions so obviously we're using surveys to to measure this as as with all of our stuff and that gives us the ability to to ask people about how they're feeling this is psychometrics which is a key part of um Behavioral Science um and because we're able to ask people these questions we can then go and do research and find out what drives individual productivity and and what indeed that leads to in terms of the benefits of the organization and what we found in 2019 when we looked at this is that productivity um is something that you can change you can make feel make people feel more or less productive um so that culture of psychological safety that I just talked about that drives increased productivity it helps people feel more productive um the other things that help Drive productivity are tools uh tooling that is uh easy to use and that um people find to be useful in achieving their goals being able to find the information they need uh quickly and easily through internal search tools and external Sear SE tools so internal search tools are tools within your organization to find um code or examples or or the information you need to get your job done and then external tools obviously outside your organization um things like Google and stack Overflow and and so forth so those things all Drive improved productivity the other thing that drives improved productivity is reduced technical debt so technical debt um this is a a term that was coined by uh Ward cunning and it's basically uh when your code bases is easy to work with because um people fix bugs there's good test coverage um people fix um problems with code quality or or poor design um people clean up behind themselves uh deleting things that aren't used anymore um people have experience in the uh the technologies that the systems are implemented in and they can easily and effectively debug them and and so forth so so when you pay attention to technical debt and you take care of these kinds of problems that drives increased productivity how do you do that well three things we found help with that first of all Loosely coupled architecture which I talked about earlier secondly code maintainability which is when it's easy for developers to find reuse and change code across the whole organization's code base and being able to easily manage dependencies as well and then finally um effective monitoring and observability also helps reduce technical debt um you know perhaps because it makes it easier to debug things so all of these things help um reduce technical debt and that in turn drives improveed productivity what does productivity do for you well first of all it helps with this thing called work recovery work recovery is the ability to cope with work stress and detach from work when we're not working so um if you uh if you have good work recovery that means when you're not working you're able to put it out of your mind and focus on other things outside work um and that you're better able to cope with work stress so people who are more productive are able to more easily separate work from things outside work that they find it easier to deal with work stress and that in turn drives lower levels of burnout burnout is that feeling of kind of hopelessness and ineffectiveness that you can sometimes get when you've been stressed out for a long time at work um so burnout is a very serious mental health problem that unfortunately is very pervasive um in Industries like technology where we have high Tempo High consequence work you can reduce team burnout as we saw earlier through implementing uh continuous delivery practices lean management and product management practices but you can also do it um by through through improved work recovery which in turn is driven by productivity another interesting titbit is we found that years of experience was not a factor in driving productivity people who are who are new to the industry can be as productive or can feel as productive as people who've been in the industry a long time finally I just want to end with a few words about coid because obviously you know it's important to talk about um remote work and coid in the context of productivity so there's some brand new research that's just come out a few days ago um from uh GitHub so my co-founder at Dora uh the principal investigator of This research program I've been describing for the last 40 something minutes uh Dr Nicole forren she's just um released these three reports um at GitHub where she now works in the state of the octopus and one of them is about productivity and they analyzed a whole bunch of data from GitHub to find out the impact of coid uh and remote work on productivity and there's this really interesting titbit um they're not using survey data for this they're using systems data from um from GitHub so it's uh slightly different research methodology um but it has some kind of tantalizing and interesting um findings which I think uh definitely definitely go and check that out there's three reports there um but one of the things they find is that activity on GitHub has stayed consistent and even increased throughout the pandemic and the shift to working from home uh and this sustained activity through these large shifts in the way we work shows that flexible tools processes and solutions can support developer productivity and even continued innovation in the face of disruption so I think that's really good news for the future it means that um the tools and the processes that we have can support working in these uh remote uh in these remote ways that we're seeing today and hopefully that will mean that um when we uh you know hopefully in the near future have a vaccine and and and uh and coid is is uh taken care of um we will still be able to preserve some of these ways of working because we have found that um you know we're able to support develop of productivity in spite of that so definitely go and look at that research and everything I've talked about today um all those different capabilities uh you can find those on cloud.google.com devops our whole research program six years of state of devops reports all those capabilities I've talked about deep Dives are all available at cloud.google.com thank you very much for your time I might not be on slack right now because I'm uh in the UK but I will come and respond to your questions on slack thank you so much for your time