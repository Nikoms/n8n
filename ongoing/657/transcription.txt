okay let's get started so I've Had The Good Fortune of speaking at the Q2 Center a number of times over the last decade I am that old and I have come to the conclusion that this is by far and away my favorite room the reason this is my favorite room is that the audience has to really want it right because on the ground floor it's the closest rooms to the pub you've got the rooms on floor three which is like well I've had some food and I can't be bothered to get anywhere else I kind of just roll into those other rooms but for this FL this room you've really got to want it you've got to go through staircases and lifts and fight through the hordes and not be distracted by the bean bags downstairs which is normally where I hide when these particular events are on so thank you so much you are my kind of people so thank you indeed for coming along we're going talking today about is the definition of insanity what we think it is and really discussion about how we can or some fundamental things that we can do to make our distributed systems more resilient more robust um and these really are what I think are some foundational technical things that you should be doing if you are building a distributed system and you want it to have some semblance of resiliency and robustness uh this talk is partly the outcome of a book I've been working on for about a year now called was this and it's um it's in Early Access now you can get more information about it over at my website there's about five chapters up at the moment including the chapters that I'm talking about today um the full book should be out towards the end of the year but we are going to be focusing today on Three core ideas that I talk about in this book timeouts retries and EM potency so timeouts right timeouts knowing when to give up on something retries knowing when to try again and item potency which is knowing when retrying again is actually going to be safe we'll also maybe along the way be discussing this particular quote to see if either a it is valid and B whether or not it's what we think it is let's start out though by talking about the context in which we are operating don't worry there will be slide downloads at the end I have QR codes for you uh let's talk about the world in which we are operating which is in the world of distributed systems it's very worth explaining what a distributed system is because they're actually quite fundamental and they're everywhere and even if you don't think you're building one you probably are technically speaking a distributed system is one where two or more computers communicate with each other via networks the more distributed these systems become generally the headaches also increase but this is fundamentally what a distributed system is so here I got two computers and they are communicating with each other via Network sometimes you're doing that quite directly you're opening up network connections you're sending bits and bites yourself sometimes you're doing it indirectly maybe via programming of traction you're using grpc for example still using a network maybe you're using a message broker maybe you're using a file system to communicate between computers it's always networks underneath all of that saying a distributed system is two or more computers connected by a network is a very dry description of it because it doesn't really speak to the the sort of horror pain and suffering that comes from anything related to networks and indeed computers and indeed people and even rabbits which we'll get to a little bit later on this is actually my favorite definition of a distributed system which comes from Computing Pioneer Leslie Lamport a distributed system is one in which the failure of a computer that you didn't even know existed can cause your own computer to be unusable Right Things Fall Apart and if you really want things to fall apart quickly use a distributed system things do tend to collapse quite a bit bit now I'm not going to in this talk try and talk about all the ways in which we can stop these systems falling apart but I at least going to deal with some of the fundamentals and behind it all there are these nagging challenges that we have to deal with now there are lots of different ways of framing the challenges of distributed systems such as the fallacies of distributed computing which is one of my own personal favorites I think Kevin's going to be talking about that a little bit later on but I've realized through my own work and research and looking into things like cap Theory and harvest and yield and all this stuff that fundamentally all of the challenges of distributed systems from a developer point of view come down to just two things firstly you cannot beam information instantaneously between two points I know that theoretically this is doable with something called quantum entanglement where you can mirror the electron spin States and that is theoretically doable but and this is very important that is not a networking protocol in addition I believe it only works for read States so it takes time and how long it takes is only partly under your control the second golden constraint if you will of distributed systems is sometimes you can't reach the thing you want to talk to this is it this is everything now The Logical conclusion of all of these things is lots of complexity however I always find that when you find yourself lost in a very something weird going on having these rules at the back of your mind and realizing that you only have partial control over these two factors is important you do have some control you do not and never will do have total control over both these things and once you accept that I find that most of the complexities of distributed systems just end up actually being Common Sense hidden behind flowy languages and the vague marketing of various vendors we are going to start by talking about timeouts timeouts are basic they are fundamental and they speak very much to the fact that you can't beam information instantaneously between two points and that sometimes the think to talk to isn't there therefore we need timeouts so what is a timeout a timeout is a threshold after which we're going to give up we tried doing something and rather than waiting we're going to give up so we're specifying a threshold and once that threshold is reached we give up so in this situation here I want to go make a payment I say can you make a payment and I don't get a response at a certain point I go right I'm done it's probably worth just exploring briefly why we even have timeouts right why not just wait forever because you don't want that let's talk about why well firstly we just have the problem of computing resources If one computer is waiting for another computer to do something you are tying up Computing resources yes even if you are using some non-blocking extension and think you're all asynchronous there are Computing resources tied up if fundamentally your computer is maintaining a network connection waiting for something to happen right so if you're waiting forever Computing resources do get tied up you can mitigate this somewhat non-blocking AO can help for example but it can't eliminate that so if I'm waiting forever and new work keeps arriving I I've got more proportion of my Computing resources both on the client and server are now potentially contended doing stuff and this is an issue because as you start to use up those Computing resources things start to go wrong systems start to get slower which can make timeouts worse systems can collapse and things get problematic so we don't want to just wait forever because resources are tied up resource contention is a problem we also have the issue of course is that some times we have these irritating things in our systems called human beings and human beings are waiting for things they are not going to wait forever and in fact if you make make them wait too long they might not do what you want them to do give you a slight case study which help this is my first sort of indoctrination into understanding that getting timeouts right was important this would have been 2008 I want to say and I was helping uh sort of re architect a site for selling amongst other things used cars new car cars motorbikes and things like that it's a UK based company and we had uh lots of old websites for selling different types of products and we were bringing them all together under one system because there's actually a lot of commonality between these different products used cars happen to be the biggest market so here we are we've got our application which was called saon for reasons hopefully you don't have to go into but this was basically an application where we were gradually kind of absorbing the functionality of all these old websites in this particular system and normally at Peak uh each of our nodes would be running between 30 to 60 concurrent requests which is not much at all these machines were had loads of excess capacity they could have handled more requests they wanted to but even at Peak this is pretty good now above our app we were taking in about 8,000 requests per second which was pretty much cashed entirely within a using a system called squid that's sat in front of all this so with a lot of lad coming in these were basic cash misses load quite small um however what something went wrong we our site started off uh started behaving quite slowly and then fell over in a very quick um short space of time and we were seeing a spike from our these nodes normally handling between 30 to 60 concurrent request to handling over 800 concurrent requests per machine and this is with a Java runtime um where one connection equals one operating system thread so now all of these machines are now trying to schedule and prioritize 800 plus threads so this was this this was excellent Hardware by the way it wasn't that excellent so net result was all of those threads blocked waiting on the machines that caused complete CPU saturation IO saturation the whole system ground to a hole it went from everything being fine to everything not being fine in about half an hour luckily it happened during the day so we were all caffeinated and we could deal with it properly right it turned out there was an application for the downstream that was causing all the issues one of our websites uh was behaving in the worst way anything can behave in a distributed system which is it was IGN acknowledging a request and then doing nothing so you could open the connection you could send the request and it would just go and it would do that forever and it was completely and utterly wedged in a way we'd never seen before now we actually restarted the Caravan application and it was fine again and obviously we had to work out the fix but that failing should not have caused the whole system to crash turned out it was largely not entirely due to timeouts when a request came into to our application said I want to see some Caravans we would take that request we' go get a you get a worker out of the connection pool and then use that to establish the HTP connection to the Caravan website this is standard connection pooling works in the same way in net work same you know if you use poly the built-in stuff in net same thing in Java connection pools are ways of limiting the number of outbound band connections you have you'll be doing this even if you don't realize it so you pick up a worker and then you use that worker to make the call and so that was how you'd establish the call out a caravan site so it was taking a long time to respond so a lot of the workers were now tied up waiting for the Caravan site to respond and it was a problem because while we were blocks waiting the users who had gone to look at the Caravans got bored and they had refreshed their browser that's a problem because the original request they put into our system is still there they have refreshed their browser and then it didn't work so what did they do again they really wanted to see that Caravan they hit refresh again and when that didn't work they kept refreshing even more annoyingly these other sites working per perfectly fine but the connection pool was shared and so no request of getting through to those apps either not great the biggest issue and there were others was that we weren't timing out quickly enough when you got a worker out of the connection pool the default behavior of this particular connection pool is the Jakarta Commons one uh was 30 seconds so you'd wait 30 seconds before giving up even in 2008 we knew that our users would wait 10 seconds or less right they're not going to wait 30 seconds so that was way way too aggressive even worse when you went to the connection p and said can I have a worker please there was a timeout specified for that and it was set to minus one which means it would wait forever and that's where the fundamental problem was this was default Behavior by the way these two numbers basically took the whole system down the connection pull was exhausted so nothing else could happen all those requests coming in were blocks waiting on the connection pole and even if someone hit Refresh on their browser those connections didn't go away now there's a lot more we could we did with this system other than fixing the timeout I can do another talk we talk about bulkheading and circuit breakers and rate limiting and load shedding and all those other things but we're here to talk about the timeouts getting timeouts right is kind of hard if you get a timeout Too Short you might give up on something that may otherwise have worked in which case that's just wasted effort and it could be even worse if that then causes you to then retry if you wait too long you can increase the resource contention to the point where the system becomes potentially unstable and so trying to find that balance is is kind of really tricky so if you're not sure right now if you've got the right timeouts what do you do well one of the most important things to do is to understand what is normal system behavior when things are operating well what do we normally expect in terms of how long things take and ideally you'd put you'd put this up on a histogram so histograms are really fantastic ways of visualizing information this type of information what a histogram does is it's showing frequency so as we go from left to right we are seeing calls that took longer so the calls over here took 250 milliseconds and the calls down at the end took 10 milliseconds we going to assume that's going to be a cach hit of some sort and so as we go up that's the frequency so you can get start to get a sense of the shape of your response times histograms are very very useful for seeing patterns so we could say look we've got some weird outliers is that a problem we'll come back to those a bit later on and you might start saying well actually look the vast majority of our calls completed successfully around here so you always starting to have conversations about where you place these lines don't do averages averages are useless absolutely useless for cheating these things it's all about looking at the the distribution and the shape this is useful so what is your current behavior when things go well were these lines normally that's a good starting point if you don't have the ability to extract that information from your systems today get that ability in there the next piece is then to Overlay user expectations how long are your users going to wait we were waiting 30 seconds how long were our people actually going to wait for a site a page to load now the annoying thing was we already had targets defined we already knew that our render time at the browser was was 4 seconds and that was already something we were working towards so we had a number in mind and yet we had a timeout that was way more generous than that the third thing you need to do is to make sure you can change your timeouts without changing code and this is quite important partly because you're going to want to check your timeouts right by doing some load testing and playing around with some numbers but also because if things start going weirdly wrong in production you want to be able to fix it now we'll come back to a real life story about why that's so important a bit later on fundamentally though time out is All About Us prioritizing the health of the system over the success of a given request that's what we're trying to do here in general when you're looking at timeouts we're thinking about system performance and behavior what you normally want to be aiming for is a fairly consistent Behavior right so we want ideally if you're thinking about say the response time of a service you don't want a huge variation of the how long that operation can take when it works successfully you want kind of Fairly consistent understandable Behavior and the reason that's important is because how do you know something's gone wrong if you've got a huge variability if a core could take anywhere from a second to 10 minutes to behave successfully return successfully that makes it quite difficult for you to set things like time or trigger alerts when thresholds are reached right so this is another way of saying being inconsistently fast might actually be worse than being consistently slow four things that work right so here's one histogram and here's another now the number of calls is exactly the same the average response time is also exactly the same however the latency here is a much tighter bound so you'll probably in General T it much easier here with a sort of a more compressed latency histogram like this to reason about is it behaving correctly is something going wrong is something going arai but again you can't even reason about that unless you can see these pictures these can also help you understand what these things are these are what we often call tail latencies otherwise known as sort of high percentile latencies these are outliers and when you have a large number of calls there's always a chance you're going to get some outliers these these things just sort of happen sometimes sometimes that happened because you had a machine that was unhealthy you had a bit of network congestion a packet went down the wrong leg of the internet it could be structural issues I've had this before when we were hitting a machine that was still running off spinning platters rather than spinning running off ssds for example although we all thought the instances were the same so the problem with tell latencies is partly they pull out our understanding about what is our normal successful response time bounds that's one issue so it's going to distort our view of the world but the other bigger issue is these tend to be human beings if these tail latencies result in human beings being unhappy that's going to be an impact right um and tail latencies can get worse as you get more distributed and so if you're looking at something like a microservice architecture we tend to push to be towards being a bit more fine grained if you also have some tail latencies in there as well you can find these problems start to magnify so let's imagine we've got a scenario here where the chance of one of our calls effective being a toil latency is one and 100 so one and 100 calls between these two services will Spike for some reason now if we take that same frequency and now we do a fan out call and each of those fan out calls has the same kind of probability we see a drastic increase in How likely we are to be affected by a tail latency let's imagine a call comes into a service which in turn does some parallel processing across five machines if each of those also has that same frequency or tail latencies the chance of our initial call being impacted by that tail latency goes from being one in 100 to five in a 100 so we see a big increase in How likely you are to be affected by tail latencies from an end user point of view as you increase the parallelism uh Mark Brooker who's got some awesome stuff all about this has done some visualizations of this so these L basically latency histograms and as he ramps up the number of calls being done in parallel you start to see how tail latencies can really warp our kind of perception of how long well the reality of how long things take so it's p animations the number of parallel calls are increasing so these are the latencies which are affected by the tail latencies and these are the ones that aren't so as we go we see a larger and larger increase I don't know what the colors aren't coming through on that one so just increasing the parallelism increases the chance you're going to see that impact it also of course gets worse with sequential calls as well right same problem starts to occur I mean this is bad anyway from an overall latency point of view when you have lots of Serial calls because your endtoend latency becomes a problem and if you've got a large variability in latency for each of these individual calls that that sort of that sums up you get an even larger distribution here so you know in this example he's done the similar this is another one from Mark Brooker where again what we're seeing here is as he increases the number of Serial calls same probability for any individual call to be a tail latency you start to see some really odd warping effects initially it's pretty much the same and then these are the tail latencies here and so as we increase the number of Serial calls you start seeing this bigger and bigger shift to the right I mean lots of Serial calls aren't good anyway if you want to get into I could do a whole talk on T latencies don't have time to go into how they happen and why and how you fix them but a good starting point would be the tailor scale um which is sort of talks about how you do like request hedging this is by Jeff Dean and um and L baraso and also Mark brooker's original writing on this stuff which is really really great both of these are highly recommended so we' talked about timeouts at a certain point we have to give up so if we're going to give up at a certain point the question is what do we do next well this is when we get into retries we start thinking about this quote the definition of insanity is doing the same thing over and over again and expecting a different result is that actually insane because I would argue it's not at least in the context of a distributed system because we know from a distributed system that sometimes you can't reach the thing you want to talk to and there a whole host of reasons that might cause the thing you want to talk to not being there that might actually be shortterm issues that might be ephemeral issues maybe you were loading a web page and somebody who's definitely not the Russian military cut you know a suby cable but it wasn't them definitely wasn't them all right they weren't look there were nowhere near it when it happened and if I refresh the page my traffic is going to get routed via one of the other links we're quite fortunate in the UK where these things happen we don't get fixed actually I have actually lived in places where when this does go you do lose the internet right but we're quite fortunate that we have lots of redundancy around these things it still does have an impact I worked in one place I worked in leester my first ever job and I worked in this these sort of uh it's an old industrial estate and they basically reused ducting that was there for like pipes and things between the buildings to also run the network cables um and uh I don't know if it's in the middle of the countryside in last this year and um one thing in the countryside that loves channels underground rabbits and if I've got a friend who actually keeps rabbits has house rabbits and the thing they love more than anything else in the world is insulation around cables they it's like crack cocaine for them so basically the rabbits moved in and they just ate the network cable right you can't handle that in your code right you don't have the only way you have control of that that situation is if you want to go down uh late at night with a shotgun it's not necessarily very nice thing to do these things occur though I mean we know that things sometimes fail and that's why we have low balances which one of the reasons we have low balances right I make a call that order instance has having an issue maybe it hits a machine that's just being restarted or just being done by the out of memory killer on kubernetes or whatever else so that had an issue so that call maybe I Ed that call out or maybe the call just failed the connection didn't even establish in the first place but that's okay because if I retry the load balancer may be able to route my call to a node which is actually working and so we know this is what happens and that's why we have low balances that's why we also know that retrying makes sense I'm sure lots of you I mean how many people here are using poly in net that's about half of you right I suspect you're using the retry policies and po which is a lot right because you know this is a thing so if at first you don't succeed it might be worth trying again this is absolutely fine and sensible how many re tries one two 50 now of course if you've got a sense of the overarching time out or how long your wait your your client is willing to wait the number of retries that you're going to take into account has to take that into account as well right you've got the timeouts for each individual call but they sum up if you retry too much you might actually overload a server I make a call I time it out I make a call I time it out I make a call I time it out if you retry too often remember a lot of time those Computing resources might still be timed out or might still be tied out until the server can process them even if the client has given up so therefore we set a maximum number of retries because we don't want to overload our servers next we have to consider delays between retries this is a problem that hit Square so Square had a large scale H think 2017 multipath which is their authentication system internally um basically was get what got restarted and it was try to establish a connection with reddis to put out his information and the Pol basically redis was quite heavily loaded the clients the multiplas clients would do 500 retries right with no delay between those retries and that was hardcoded and so what happened was multi passes kept getting hammered and people were restarting the clients just think oh that's going to fix it and that just increase the load now those values were not were in code they were hardcoded they fixed it but now if you find a problem like that your timeout is wrong when you don't have the right delay and it's in code you've now got to go change code recompile maybe probably retest redeploy if it's in a text file you just go change the text file so put your time outs and these things in a text file and yes delays are sensible to put your retry limits and all these things now the retries get interesting I'm sure most of you uh if you're using something like poly or resilience 4J in a Java world you're probably using one of the default retry policies which will give you a exponential or semi- exponential back off between the retries so another words rather than having a fixed Cadence we actually have a variable Cadence between retries and that's quite common it's not the only thing you need to do though what you can get is when all the clients start to synchronize is you can get like waves hitting a server causing problems so in this scenario here right we've got the calls coming in and we're hitting a threshold which is kind of where the server starting to Creek a little bit and so a portion of those calls above that threshold start getting timed out right so what happens is some of those calls time out and so they're going to get retried because they all timed out around the same sort of time if they've all got roughly the same delay they're all going to retry in the same duration so they all come back as a cluster right so this green area here is this first retry and of course that's still pushing us over that threshold so portion of those time out and the other new calls time out as well and if we wait the same period of time you can start to see these things magnify so if you have very set durations between the retri of clients even if by the way those clients have exponential backoffs and exponential backoffs cause problems for user facing stuff anyway we still have an issue so the the way we solve this is by adding Jitter so networking Jitter is like a variation in latency and we're basically inserting artificial Jitter the way we do that is that your clients will add a random amount of delay so there might be a normal delay we're going to wait 200 M and there'll be a plus or minus some random amount and the idea here is that we're going to space out we're going to space out those calls the idea here is that we smooth off these Peaks and we Bridge them out so the same number of calls in this scenario Here and Now much more spaced out we're trying to reduce the Peaks we're hitting and actually also reduce the troughs as well so again use a good connection Library they will have these values allow po absolutely lets you specify this stuff there'll be some defaults in there but now you at least know why they're there and you might even want to be able to change them if you can do some load testing and view your response times in a histogram like that you've now able to go start making some tweaks and seeing what happens but in general like one of these graphs is better than the other the same number of calls and I definitely would want the one on the right the last thing we're going to talk about is in many ways the trickiest aspect a lot of what I've talked about so far I think things that you can sort of retrofit into existing applications right okay I can go see where my connection pools are make sure the timeouts are correct because probably you're using things already that give you these capabilities so you can go in you can make the observations you can start doing the tweaks the next bit gets a little bit trickier and this is asking asking the question rather is it safe to retry something so here we've got an operation where the order service wants to send me some money very generous of the order service light think comes from one of you you want to pay me £100 so you say pay Sam £100 but you don't get a response now you're desperate to give me money um I'm desperate to take your money I'm buying a house you but you're so desperate you didn't get a response I really want to make sure Sam gets the money but we've got a tricky problem now because from the point of view of the order service if you don't get a response there are kind of two equally likely possibilities the first possibility is the request to me to say pay sam1 pounds the first possibility is that that never got picked up or processed so the first possibility is the request was not processed in the first place and that's why we didn't get response because the request wasn't processed so maybe the request got lost on the way maybe the the server picked up that request but maybe crashed before it could complete processing and perform the right that's one possibility there's a second possibility and this is kind of where things start to get a bit iffy the second possibility is you sent the request the request got processed but the response didn't get to you and again this could happen because for example let's imagine in the payment server I was going to send the event I was going to send the response rather and my server crashed before I could send a response but I probably send the response after I've done the right this is partly why people use transactional outboxes right to avoid this problem but even with the transactional outbox there still things that could go wrong that meant that that response never gets back to me certainly Could Happen even say case where we just communicating over HTP there's lots of situations where that could happen so from the point of view of the order service it's possible the money got paid and it's possible the money didn't get paid and you don't know which is which it's like inside this box there's either a dead cat or aive cat and in either case I want my1 pound right so what' you do now if you say pay S100 and you don't get a response but it was actually paid and then you say pay them1 P again in this situation from your point of view you might have the undesirable situation you now actually paid me200 to be really clear I'm pretty happy with the whole situation but it's probably not what you want you'd also think at this point Sam people don't build systems like this I can go through about five or 10 different case days are dug up of payment services and systems where exactly this thing has actually happened around money being drained from people's accounts so what do we do here this is we introduced a concept called item potency and this is a mathematical concept which I do not understand because I'm bad at maths but I think I'm good at common sense and for me there's a very basic kind of construct around well where thinking about item potent operations right an item potent operation is an operation that you can apply multiple times without changing the result so it's something we can safely retry so in this situation here this operation as we've described it is not fundamentally idem potent because carrying out the same operation a second time should still only yield me being 100 up but as we've got it modeled here is actually going to result in me being2 200 up so we say his operation is not fundamentally em potent so how do we make it em potent well there's the best way which is most painful and a less good way which you might have to do if you can't retrofit it in so we're going to look at request IDs and we're going to look at server side fingerprinting okay and ideally you want do request IDs request IDs are actually really straightforward it's a very very simple idea we're going to generate a unique ID for that request and that's going to be used to identify a specific request and this is going to allow a server to identify that it's seen that request before and ignore it very straightforward so I PID some1 pound but now we introduce the content of of a payment ID 456 that first payment went through but something went wrong with the response I do the I say I really want that1 I send it again I send the ID along and the payment Service is like sure we've already paid that money but yeah it's done really really simple lovely easy to do don't confuse these with correlation IDs right because a correlation ID is typically an ID used to correlate multiple calls together this is a single request ID so you do an ID fit so if you've got like a a a chain of calls you might have a correlation ID for the whole chain but you would have a request ID for each individual piece um this also wouldn't be the same thing a span ID in say op using open Telemetry because with open Telemetry you do track each individual call so span IDs actually change so this is actually a different thing to all of those really really simple ID the problem with this is really straightforward you have to change the client server protocol for this to work the client has to send the request ID and the server has to respect it so this makes building a protocol where operations can easily be made em potent quite easy if you think about it up front which is lovely if you have a time machine but if you're discovering this stuff today and you're like but Sam I've got a complex system which we don't have putting request IDs in and yes we can start putting them in but that's going to take a long time or we've got Legacy software doesn't behave in this way well then then what can you do and that's when we look at the other piece this which is seriz fingerprinting and this is where the on the server side when we get that request we're going to generate effect you a fingerprint of that request and then when requests come in we check their fingerprint and see if we've already processed them before this is kind of the game the only game in town really for item potency if you have no ability to change that client server protocol and in rare situations you would actually use both of these things together like the AWS API use both these things together if you have time I'll talk about why so if we think about EST I'm sending here so a simple payment request I'm sending and I can see the field a customer ID a payment amount and then so i' got the header and the body and again the concepts of headers and bodies are kind of HTTP specific Concepts but this could be a message right it's the metadata on the body of the payload right and so I would take the body generate a hash this is an md5 hash so I can say well the request ID is that that was processed and I could write that to a database write the payment nodes could say that's been done I write write that out to a database so I know that's been handled a second request comes in it matches we're good to go the issue with a server side ID Ser side fingerprinting is there are lots of corner cases that make it a bit difficult and in certain situations make it really tricky depends a lot on the nature of your API and how you the interaction how you expect it to be used but I'll run you through a few kind of pitfalls around servide fingerprinting which is why I don't think is what you want to do if you can avoid it the first is kind of what I would almost consider to be client errors so in this example here we've got a protocol where we have a Tim stamp of when the request was generated and the way this ID this the way this client server protocol has been designed that timestamp is put in the request so when I do a retry the request the time stamp changes so if I'm generating an md5 hash of both of the request bodies here those hd5 hashes don't match right so that's a problem they are the same request it's just the time stamps changed but the hash looks the same so couple of ways to solve this the first thing way to solve this is to say what we're going to do is effectively mask off part of the body so we're only look at certain fields in the body that gets a little bit tricky right because when new fields are added do they need to be accounted for or not do you go for a kind of a whit listing of approach a blacklisting approach so that's not ideal but again often if you're you're using this approach because you're retrofitting it into a system you can't easily change so some kind of masking might be needed now of course the ideal approach here is to say well what is that Tim stamp it's really a piece of metadata that should actually move up into the header and that's conceptually the right place for it to live however if we can make a change like that we can change the client and the server and if we can change the client the server just use request IDs so just so bear in mind and you know this is a fairly nicely structured payload right again Legacy software it isn't always like this it could just be some Jason blob monstrosity with no schema and you've got no idea what's going on inside that and in those situations you nor normally need some kind of exclusion and so that gets a bit tricky and again often when you're worrying about item potency it tends to be for operations that are quite important and so getting these things wrong is is not ideal there are other issues here let's consider a situation where you love my work so much you want to send me100 pound every week so you pay me100 this is like the worst kind of NLP this stuff is supposed to be like much more subtle than this I don't have a patreon don't worry right um I should get a patreon so here's the md5 hash for this operation great time passes a week later you think need to pay something another1 P still like his stuff and I go to send it again but the hash is the same because fundamentally you're paying me100 the hash is identical so in this scenario we say well actually now what we probably want to do is have an md5 Hash a fingerprint that's may be only kept for a certain period of time maybe we keep it for a week or a day or an hour or a minute and exactly how long you keep that for might depend a bit on your business but now we're starting to get in some of those gray areas right which is not ideal and but probably want to do this right but then what about a scenario where you really do want to do the same thing multiple times in a short space of time a good example would be spinning up VMS so I'm going to spin up a VM and I want spin up five of those VMS I might do that in a for Loop so I'm calling I don't know the API the aure apis and in a for Loop saying do the same thing five times and the requests look identical I'm doing a very short space time and it's completely valid now again the zero apis and the AWS apis require request IDs so they know that each of those is different calls but you sometimes do get scenarios where you do want to do that in the same period of time so again there's all these nasty Corner cases around serde fingerprinting I think it's also valid by the way um this is talking more generally you do get sort of client type errors with these situations where even with request ID someone sends a request and then they retry the request but they do change the body I actually think it's valid for you to error at that point if you want to I think it's a little bit up for grabs but I would argue that if you're retrying an operation with the same request ID but you're changing the body that you actually error at that point the AWS API do that and they do that partly to educate the user right you shouldn't be doing this now for you to actually have done that it means you're not using their apis you're going you're not using their sdks you're going straight to under apis but that's something for you to consider inside an organization where you might say look when you do the retries don't change anything and you may still want to do some Ser side fingerprinting to pick up the fact that the body did change so you can then report back an error or maybe you still carry you say look the operation you ask because in that situation it's like what do I respond with so if you I sent the first request to you and you did that first request and I processed it for you great but you didn't get the response and you then retry it with the same request ID but now you've changed the body what response am I supposed to give because I did the first operation not the second so it gets very confusing so typically you might do suicide fingerprinting on this even if you can do request IDs pely to pick up those kind of bad client behaviors I won't say it's going as far as in in an environment where you've got untrusted clients but certainly for this is why you know AWS and isur do is because effectively anyone outside your company has to be considered to be untrusted in this sense but it's also I'd see it's about educating the users of your services as well well so again this is a kind of an open question I think it's got a very straightforward answer when you do retry an operation that previously had worked what response should you give well the answer is you should give the same response that you g you would have you tried to give the first time I gave you response the first time you didn't get it and nothing is happening here so I'm just going to give you the same response again so that's the answer right so when you do a rryy and you're retrying something that had actually worked and the server has identified that we already did that you ideally want to give back exactly the same response semantically yes it works no it didn't if the first one didn't work the retry doesn't work either right because you got it you tried processing it and you couldn't then you start having to deal with what error code you retry which you don't which is again conversation I could do a whole conversation about HTP status codes but nobody wants that I've Been Told so in this example I save the payment ID I sent the it was an accepted you didn't get that for some reason you do it again I send back the same accepted header as the same accepted response now bear in mind when you send that second response back the semantics is it worked I'm letting you know it worked you can still be free to have some information that's varied in there for example I could put some information in the header to say it's the body is the same it worked but in the header you can say this is the 15th time I've told you you about this and I'd wish you'd stop asking right you can still put things like that in it semantically the response is exactly the same right so timeouts retries item potency item potency tricky it's actually simple if you can just change the client server protocol if you can request IDs are going to make your life so easy um if you if you go and have a look around all the sort of the public face ing apis for companies like stripe and square and AWS and Azure and all these people they all have request IDs for any operations that are right for this reason you should put those things in as well doesn't just apply for HTTP based communication it absolutely applies to anything over message Brokers as well request IDs are very much a thing you should do they're easy to put in and easy to handle retrofitting them is difficult with Legacy software or CW you can't easily change do consider side fingerprinting in many situations it might be absolutely fine just do be aware of the downsides of doing that so doing the same thing over and over again may be really sensible um but only if you can do it safely you don't want to start draining people's bank accounts speaking of doing the same thing over and over again here's that Einstein quote wasn't it the definition of insanity is doing the same thing over and over again again and expecting a different result only he didn't say it the thing we keep doing is saying Einstein said this quote he didn't there's no evidence he ever said that quote so maybe that's a definition of insanity is us saying he said a thing he never said in this day and age of us hearing facts that apparently made up I think it's important to do your homework and check who said what Einstein's never said that and he's not around to defend himself and it's kind of a fun quote and useful but actually in the context of dist systems it's really bad advice right the best advice is doing the same thing over and over again might be a good idea until it's not but that's not as catchy right is it so in summary sometimes you should give up timeouts are completely and utterly appropriate to find a balance between keeping users happy and keeping the system stable you likely already have have the ability to specify all the timeouts you need just by using the software you're already using the question is do you know what those timeouts are start I would suggest by just looking at those histograms if you can get them for your services at least start off by getting them kind of for the user facing endpoints start understanding what they're showing you double checking them the problem is often you only know timeouts are wrong when you start getting in issues like the ones I talked about before and that might be a bad time to find out about it retrying absolutely can make sense to a point so think about how many type reches you want to make and the gaps you want to leave between them and remember that's going to be an overarching timeout for something else blocking coming in I would strongly suggest using a decent connection Library light poly light resilience 4J those things also have some really useful um add-ons to these kind of Concepts you can look at things like token bucket and leaky bucket um connections for things where basically it's a different way of doing limiting it's really useful those are Advanced things just get your timeouts and your rry policies right first they give you the mechanics to do it and they all that they can do is give you default Behavior they but that they don't know what your application is doing so understand them right if you do want to retry which you probably do you really need to make sure that your operations are item potent and if you can do that from the beginning request IDs make your life easy that's kind of all I've got if you click on this thing it's a QR code um you you can get the slides um you can also if you go to my website you can sign up to my mail list I do like a list a mail once a month which is just stuff I found that's interesting I also share bits of my research for the book and the progress of the book as well the latest chapter on the book is now available in Early Access it's on talking about thundering herds so you've already got chapters out there available on timeouts retries and item potency rate limiting so I talk about low Ching back pressure circuit break it's a whole loot of different types of kind of ways in which systems fall over under load if you don't want to sign up for an O'Reilly account to read that book in Early Access you can get like a 30-day free trial and watch it and read the book then it's fine um but thank you so much indeed for all your time now we do have time for some questions anyone got a question for me yeah anyone question at the back there I my I'm an old man so if you could come forward a little bit it might make it easier for me to hear I've only I see I feel bad now because I've made you walk up here to come and watch the talk and now making you walk even further forward I so uh you said that under certain circumstances it could be more advantageous to have both fingerprinting and request ID yeah but if understand correctly request IDs are supposed to be fairly fullprof right that well so the scenario where you'd want both is a situation where you can't 100% trust the client so if the client does a retry but changes the parameters of the request so they say here's re here's request ID 4 I want you to do this and then they say I still want you to do request ID 4 but I've now changed the parameters in that situation you get into a confused World um so the client shouldn't do that right if I said pay some £100 and then when i' retry it I keep the same request ID but but I now say pay Sam £1,000 I might think you've paid £100 and you paid £1,000 or vice versa based on the response so reason to do both on the server side is in a situation where you you don't fully trust the client and you want to be very clear about what's actually happened so the situation where the first request ID for pay £100 I processed that and paid £100 you then on the client retried the operation but train a parameter the response comes through said yes that was paid did I pay1 or did I pay ,000 that's the reason we might do both I think it's a little bit Niche but I think it's something worth considering um and I think it really where it is useful is in a situation you're trying to educate developers about what they should and shouldn't be doing so this should only be the case where you don't have full control over both client and server yeah and I would say most micros service architectures where I work that's the case because often your service think of it like a it's basically defense me ISM to an extent but like a lot of times the organizations I work I'm managing four or five services and I've got teams over here using my services I don't control their code so if that code is coming from another team I think it could be useful to do I would definitely put it in the nice to have category and I think it's a conversation that you should have but like if you're putting these things in now uh I would have a conversation with your clients here's what we're going to be doing here's how it's going to handle by the way when you do a retry don't change the parameters uh and then and then you can say and we'll be looking right we'll send out a naughty list so I think it's a bit Niche but I think it's in a situation that if you your team is doing the client and the server bit don't worry about it as a situation where somebody else is right in the client consider it thank you you're welcome uh NE oh hang on as a gift to you for walking forward I have books to give away there you go if you don't want it you can give it to a well me person there we go thank you all right anyone else got a question for me go ahead I totally understand the the stand don't the using the request ID yeah but just on standard around HTTP there's an ID pocy key header that's been defined what do you think I I think if you're using ID I I think if you're using HTTP at that level by all means use that standard um the issue is lots of people use HTTP but aren't using it directly so um if you're using HTTP directly use it now do bear in mind that item potency key there's a lot of public examples of the request IDs out that predate that because that was added to specification later but if you're using HTP directly use that but a lot of you might be using grpc 2 for ex grpc for example in which case that's hidden from you always 99% of the time do what hdp says like nearly always is doing the right thing uh book you get a you get a book as well everyone get some B all right any other questions for me question back there oh you got a microphone we've got an assistant thank you so much go ahead um so if you're going to do request IDs and fingerprinting and you don't get the response in the first one so for the retries you were saying send the same response um so if it's the first time and you retry you give about the same response would you check for that the body hasn't changed and maybe give a bad request or something that for me is a bit of ambiguity so I would argue that that's actually an error State and it's a confusing error to give to a client the first thing you wanted to do I did the last thing you asked me to do that was trash and I haven't done it it is a confused error so but I think probably the right thing to do is kind of to error to say you kind of stuffed up here the HTP protocol does not give us a status code for this yeah so this is where you would have to probably come up with your own variation within that and it would be a 400 series so You' pick one of the 400 series errors um to put in there um I could probably pick one of that's close but yeah I for I really think strictly speaking it is an error because again if I don't give you an error from a client point of view which one of those two things actually worked and I think it's better that the client blows up um in that situation yeah book you get a book all right there we go than we've got any other questions thanks any other questions all right well you've been fabulous because you walked up here you're already fabulous when you walked in but thank you so much for your attention and your uh and everything else um and for getting up here thank you for coming to NDC it's a great conference I hope to see you again around here later today and tomorrow um if you're interested in security and security education please do go and see my friend Laura Bell who's running the SE snack Booth downstairs literally underneath this um as well uh because she's awesome and so is a cont and there lots of other great speakers to watch tonight go watch Kevin's talk later I think it's going be talking about some of this stuff anyway love you all have fun stay safe and I'll see you next time